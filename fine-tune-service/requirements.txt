# Core dependencies
torch>=2.1.0
transformers>=4.49.0
accelerate>=0.27.0
peft>=0.13.0
bitsandbytes>=0.41.0

# Data handling
datasets>=2.14.0

# GCS integration
google-cloud-storage>=2.14.0

# Training utilities
trl>=0.7.0  # Supervised Fine-Tuning trainer
sentencepiece>=0.1.99
protobuf>=4.25.0

# Monitoring (optional)
wandb>=0.15.0

# Flash Attention for faster training (optional, requires specific CUDA setup)
# flash-attn>=2.3.0  # Uncomment if using compatible GPU

# Utilities
numpy>=1.24.0
